{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghdvmIsv2jul"
   },
   "source": [
    "## 실습 [9-1]  \n",
    "\n",
    "### 1. 실습명 : N-gram 언어 모델로 문장 생성하기\n",
    "### 2. 실습 목적 및 설명\n",
    " \n",
    "*   파이썬의 NLTK 패키지를 이용하여 N-gram 언어 모델을 구축한다\n",
    "*   네이버에서 오픈 소스로 제공하는 nsmc 영화 리뷰 데이터셋을 이용해 문장을 생성한다.\n",
    "\n",
    "### 3. 관련 장(챕터) : 9.2.2 N-gram 언어 모델 (N-gram Language Model)\n",
    "### 4. 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ex4VLpId3e-T"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize\n",
    "from nltk import ConditionalFreqDist\n",
    "from nltk.probability import ConditionalProbDist, MLEProbDist\n",
    "import numpy as np\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5wazYRi07LIj",
    "outputId": "b408ddd5-fe6c-4fcc-dc44-933ab069b2cc"
   },
   "outputs": [],
   "source": [
    "# 한국어 처리에 필요한 konlpy 패키지를 설치하기 전에 선행 파일을 설치한다. \n",
    "# !brew update\n",
    "\n",
    "# !brew tap AdoptOpenJDK/openjdk\n",
    "# !brew cask install adoptopenjdk8\n",
    "!JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "\n",
    "# #!brew install gcc@8 openjdk-8-jdk python-dev python3-dev\n",
    "# !pip3 install JPype1-py3\n",
    "# !pip3 install konlpy       # Python 3.x\n",
    "#!pip3 install jpype1\n",
    "from konlpy.tag import Okt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJbbAta148Tc"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "# NLTK\n",
    "# 패키지를 이용하여 입력 텍스트를 N-gram 형태로 변환한다.\n",
    "sentence = \"나는 매일 아침 지하철을 탄다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Kvvfewcs5OR4",
    "outputId": "3accf3be-569e-49fb-830e-d637cce58dd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/edwardwon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK 사용을 위하여 선행 패키지를 설치한다.\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 입력 텍스트를 띄어쓰기 기준으로 토큰화한다.\n",
    "tokens = word_tokenize(sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "fSAEP3U65nav",
    "outputId": "4aabcad5-a640-43c1-a70d-1eb261794a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나는', '매일', '아침', '지하철을', '탄다']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "jLTfZw_fcxhs",
    "outputId": "09e44664-2b86-4838-ca72-a24aec8c572a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나/Noun', '는/Josa', '매일/Noun', '아침/Noun', '지하철/Noun', '을/Josa', '탄다/Verb']\n"
     ]
    }
   ],
   "source": [
    "# 한국어의 단어는 띄어쓰기를 기준으로 하지 않기 때문에 konlpy를 이용해 형태소를 기준으로 토큰화한다.\n",
    "tagger = Okt()\n",
    "\n",
    "def tokenize(text):\n",
    "  tokens = ['/'.join(t) for t in tagger.pos(text)]\n",
    "  return tokens\n",
    "\n",
    "tokens = tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgWgUE_N5yEf"
   },
   "outputs": [],
   "source": [
    "# 토큰을 N-gram의 형태로 바꾸어준다. \n",
    "# ngrams 함수의 두 번째 인자로 N값을 지정할 수 있다.\n",
    "bigram = ngrams(tokens, 2)\n",
    "trigram = ngrams(tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "1FTnRG9O63WX",
    "outputId": "f182814f-3870-406c-8a22-c171afae6106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram: \n",
      "('나/Noun', '는/Josa')\n",
      "('는/Josa', '매일/Noun')\n",
      "('매일/Noun', '아침/Noun')\n",
      "('아침/Noun', '지하철/Noun')\n",
      "('지하철/Noun', '을/Josa')\n",
      "('을/Josa', '탄다/Verb')\n",
      "\n",
      "trigram: \n",
      "('나/Noun', '는/Josa', '매일/Noun')\n",
      "('는/Josa', '매일/Noun', '아침/Noun')\n",
      "('매일/Noun', '아침/Noun', '지하철/Noun')\n",
      "('아침/Noun', '지하철/Noun', '을/Josa')\n",
      "('지하철/Noun', '을/Josa', '탄다/Verb')\n"
     ]
    }
   ],
   "source": [
    "# N-gram을 출력해본다.\n",
    "print(\"bigram: \")\n",
    "for b in bigram:\n",
    "  print(b)\n",
    "\n",
    "print(\"\\ntrigram: \")\n",
    "for t in trigram:\n",
    "  print(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "F0MpXv1H6_Gd",
    "outputId": "94937940-2e6d-4350-dfb3-d8800b2b4ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams with padding: \n",
      "('<s>', '나/Noun')\n",
      "('나/Noun', '는/Josa')\n",
      "('는/Josa', '매일/Noun')\n",
      "('매일/Noun', '아침/Noun')\n",
      "('아침/Noun', '지하철/Noun')\n",
      "('지하철/Noun', '을/Josa')\n",
      "('을/Josa', '탄다/Verb')\n",
      "('탄다/Verb', '</s>')\n"
     ]
    }
   ],
   "source": [
    "# padding을 통해 입력 데이터에 문장의 시작과 끝을 알리는 토큰을 추가한다. \n",
    "bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\")\n",
    "print(\"bigrams with padding: \")\n",
    "for b in bigram:\n",
    "  print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Cr25hyHn9Shh",
    "outputId": "4f1b26b9-5a25-4283-ab92-e4f3871a985e"
   },
   "outputs": [],
   "source": [
    "# 문장 생성을 위하여 네이버 영화 리뷰 데이터셋을 다운로드한다.\n",
    "!wget -nc -q https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "TS64JsKs92Xi",
    "outputId": "7d8d149a-ca02-42e5-c923-8e9edc3802e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋:  [['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0'], ['3819312', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1'], ['10265843', '너무재밓었다그래서보는것을추천한다', '0'], ['9045019', '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '0'], ['6483659', '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '1'], ['5403919', '막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.', '0'], ['7797314', '원작의 긴장감을 제대로 살려내지못했다.', '0'], ['9443947', '별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네', '0'], ['7156791', '액션이 없는데도 재미 있는 몇안되는 영화', '1'], ['5912145', '왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?', '1']]\n",
      "\n",
      "텍스트 데이터: ['아 더빙.. 진짜 짜증나네요 목소리', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '너무재밓었다그래서보는것을추천한다', '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다']\n",
      "\n",
      "문장 개수:  150000\n"
     ]
    }
   ],
   "source": [
    "# 다운로드 받은 데이터셋을 읽고 인덱스와 라벨을 제외한 텍스트 부분만 가져온다.\n",
    "# codecs 패키지는 대용량 파일을 조금씩 읽을 수 있게 해준다. \n",
    "\n",
    "with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n",
    "  data = [line.split('\\t') for line in f.read().splitlines()] # \\n 제외\n",
    "  data = data[1:] # header 제외\n",
    "print(\"데이터셋: \", data[:10])\n",
    "docs = [row[1] for row in data] # 텍스트 부분만 가져옴\n",
    "print(\"\\n텍스트 데이터:\", docs[:5])\n",
    "print(\"\\n문장 개수: \",len(docs)) # 총 15만개의 문장으로 이루어진 데이터셋임을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "XAd9C--T9_AP",
    "outputId": "fa13fa39-e9f8-4d88-e123-3a6f6bdf561b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150000/150000 [03:38<00:00, 685.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# 토큰화한 텍스트 데이터의 bigram을 모두 리스트에 추가한다.\n",
    "sentences = []\n",
    "for d in tqdm(docs):\n",
    "  tokens = tokenize(d)\n",
    "  bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\")\n",
    "  sentences += [t for t in bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "U_Pf91qqj9PH",
    "outputId": "97922410-f2b5-4994-8168-ee56bd0de800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>', '아/Exclamation'), ('아/Exclamation', '더빙/Noun'), ('더빙/Noun', '../Punctuation'), ('../Punctuation', '진짜/Noun'), ('진짜/Noun', '짜증나네요/Adjective'), ('짜증나네요/Adjective', '목소리/Noun'), ('목소리/Noun', '</s>'), ('<s>', '흠/Noun'), ('흠/Noun', '.../Punctuation'), ('.../Punctuation', '포스터/Noun')]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "gL31DVi1ld25",
    "outputId": "d85d0e9f-3eea-4156-c0bf-6dd4f1261d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('정말/Noun', 2718), ('이/Noun', 2371), ('진짜/Noun', 2232), ('이/Determiner', 2115), ('영화/Noun', 2069)]\n"
     ]
    }
   ],
   "source": [
    "cfd = ConditionalFreqDist(sentences)\n",
    "print(cfd[\"<s>\"].most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYm2U1nhndI6"
   },
   "outputs": [],
   "source": [
    "# 주어진 토큰(c) 다음에 가장 많이 등장하는 n개의 단어를 반환하는 함수를 만든다.\n",
    "def most_common(c, n, pos=None):\n",
    "  if pos is None:\n",
    "    return cfd[tokenize(c)[0]].most_common(n)\n",
    "  else:\n",
    "    return cfd[\"/\".join([c, pos])].most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "73MTcDKPoliE",
    "outputId": "8b80ad0e-cd2a-4c56-adf0-78a3fb9e5b19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('는/Josa', 831), ('의/Josa', 339), ('만/Josa', 213), ('에게/Josa', 148), ('에겐/Josa', 84), ('랑/Josa', 81), ('한테/Josa', 50), ('참/Verb', 45), ('이/Determiner', 44), ('와도/Josa', 43)]\n"
     ]
    }
   ],
   "source": [
    "print(most_common(\"나\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AaoisqGFnZaK"
   },
   "outputs": [],
   "source": [
    "# 단어별 등장 빈도를 기반으로 조건부 확률을 추정한다.\n",
    "cpd = ConditionalProbDist(cfd, MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "WrIUwvsOmv17",
    "outputId": "c10b52a2-eaf6-43e1-b8b7-7c51fad1c3bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39102658679807606\n"
     ]
    }
   ],
   "source": [
    "# “.” 다음에 “</s>”가 올 확률을 출력한다.\n",
    "print(cpd[tokenize(\".\")[0]].prob(\"</s>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPJO9Bw9sLcL"
   },
   "outputs": [],
   "source": [
    "# 토큰 c 다음에 토큰 w가 bigram으로 함께 등장할 확률을 구한다.\n",
    "def bigram_prob(c, w):\n",
    "  context = tokenize(c)[0]\n",
    "  word = tokenize(w)[0]\n",
    "  return cpd[context].prob(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "5W56LrNYs6MO",
    "outputId": "58610ee4-08f0-4cbe-d7a6-9a7d8fcacc67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4010748656417948\n"
     ]
    }
   ],
   "source": [
    "print(bigram_prob(\"이\", \"영화\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "80QHPkHXs9qX",
    "outputId": "6fae7357-5f9e-4ea4-d13f-9aec6f3d8f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00015767585785521414\n"
     ]
    }
   ],
   "source": [
    "print(bigram_prob(\"영화\", \"이\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jat3RD0LtJ8Z"
   },
   "outputs": [],
   "source": [
    "# 조건부 확률을 알게 되면 가장 확률이 높은 토큰열을 토대로 문장을 생성할 수 있다.\n",
    "def generate_sentence(seed=None, debug=False):\n",
    "  if seed is not None:\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "  c = \"<s>\"\n",
    "  sentence = []\n",
    "  while True:\n",
    "    if c not in cpd:\n",
    "      break\n",
    "    w = cpd[c].generate()\n",
    "\n",
    "    if w == \"</s>\":\n",
    "      break\n",
    "    \n",
    "    word = w.split(\"/\")[0]\n",
    "    pos = w.split(\"/\")[1]\n",
    "\n",
    "    # 조사, 어미 등을 제외하고 각 토큰은 띄어쓰기로 구분하여 생성한다.\n",
    "    if c == \"<s>\":\n",
    "      sentence.append(word.title())\n",
    "    elif c in [\"`\", \"\\\"\",\"'\",\"(\"]:\n",
    "      sentence.append(word)\n",
    "    elif word in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
    "      sentence.append(word)\n",
    "    elif pos in [\"Josa\", \"Punctuation\", \"Suffix\"]:\n",
    "        sentence.append(word)\n",
    "    elif w in [\"임/Noun\", \"것/Noun\", \"는걸/Noun\", \"릴때/Noun\",\n",
    "                \"되다/Verb\", \"이다/Verb\", \"하다/Verb\", \"이다/Adjective\"]:\n",
    "        sentence.append(word)\n",
    "    else:\n",
    "        sentence.append(\" \" + word)\n",
    "    c = w\n",
    "\n",
    "    if debug:\n",
    "      print(w)\n",
    "\n",
    "  return \"\".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "pgWQJXqRuLMF",
    "outputId": "2a218810-c33e-4ecf-ea42-87c4e5499f04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도리까지 본 영화 너무... 뭔가.. 최고네요. 하지만.. 눈물 낫다는건 또 영화에 들지 않는다. 근데 뭐야 어떻게 그렇게 착했던 윤재랑은 에바 그린 드레스 소리 듣는거임\"\"\" 에리 욧의 미모로 합성 한 가수 노래와 흥행 놓친 영화다. 사투리 연기 하나 없는 ‘ 스피드 감 넘치는 스릴 넘치는 연기를 이해 되지 못 하시는 분보다 훨 재밌구만 평점을 망처 놓은 듯하다. 영화 보는이로 하여금 불편함을 느꼇을듯\n"
     ]
    }
   ],
   "source": [
    "print(generate_sentence(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7RdPvL2AuLy8",
    "outputId": "1d4f81c7-7e6f-406a-f024-2d6abfdc7cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도리/Noun\n",
      "까지/Josa\n",
      "본/Verb\n",
      "영화/Noun\n",
      "너무/Adverb\n",
      ".../Punctuation\n",
      "뭔가/Noun\n",
      "../Punctuation\n",
      "최고/Noun\n",
      "네/Suffix\n",
      "요/Josa\n",
      "./Punctuation\n",
      "하지만/Conjunction\n",
      "../Punctuation\n",
      "눈물/Noun\n",
      "낫다는건/Verb\n",
      "또/Noun\n",
      "영화/Noun\n",
      "에/Josa\n",
      "들지/Verb\n",
      "않는다/Verb\n",
      "./Punctuation\n",
      "근데/Adverb\n",
      "뭐/Noun\n",
      "야/Josa\n",
      "어떻게/Adjective\n",
      "그렇게/Adverb\n",
      "착했던/Adjective\n",
      "윤재/Noun\n",
      "랑은/Josa\n",
      "에바/Noun\n",
      "그린/Noun\n",
      "드레스/Noun\n",
      "소리/Noun\n",
      "듣는거/Verb\n",
      "임/Noun\n",
      "\"\"\"/Punctuation\n",
      "에리/Noun\n",
      "욧의/Noun\n",
      "미모/Noun\n",
      "로/Josa\n",
      "합성/Noun\n",
      "한/Determiner\n",
      "가수/Noun\n",
      "노래/Noun\n",
      "와/Josa\n",
      "흥행/Noun\n",
      "놓친/Verb\n",
      "영화/Noun\n",
      "다/Josa\n",
      "./Punctuation\n",
      "사투리/Noun\n",
      "연기/Noun\n",
      "하나/Noun\n",
      "없는/Adjective\n",
      "‘/Foreign\n",
      "스피드/Noun\n",
      "감/Noun\n",
      "넘치는/Adjective\n",
      "스릴/Noun\n",
      "넘치는/Adjective\n",
      "연기/Noun\n",
      "를/Josa\n",
      "이해/Noun\n",
      "되지/Verb\n",
      "못/VerbPrefix\n",
      "하시는/Verb\n",
      "분/Noun\n",
      "보다/Josa\n",
      "훨/Noun\n",
      "재밌구만/Adjective\n",
      "평점/Noun\n",
      "을/Josa\n",
      "망처/Noun\n",
      "놓은/Verb\n",
      "듯/Noun\n",
      "하다/Verb\n",
      "./Punctuation\n",
      "영화/Noun\n",
      "보는이로/Verb\n",
      "하여금/Adverb\n",
      "불편함을/Adjective\n",
      "느꼇을듯/Noun\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'도리까지 본 영화 너무... 뭔가.. 최고네요. 하지만.. 눈물 낫다는건 또 영화에 들지 않는다. 근데 뭐야 어떻게 그렇게 착했던 윤재랑은 에바 그린 드레스 소리 듣는거임\"\"\" 에리 욧의 미모로 합성 한 가수 노래와 흥행 놓친 영화다. 사투리 연기 하나 없는 ‘ 스피드 감 넘치는 스릴 넘치는 연기를 이해 되지 못 하시는 분보다 훨 재밌구만 평점을 망처 놓은 듯하다. 영화 보는이로 하여금 불편함을 느꼇을듯'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(2, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wV8yp-J2U5j"
   },
   "source": [
    "### 5. 결과\n",
    "： 위 예제는 코퍼스 내의 등장 빈도에 기반하여 문장을 생성한다. bigram 언어 모델로 생성한 것이기 때문에 인접한 두 단어는 그나마 자연스럽지만 멀리 떨어진 단어와는 전혀 무관한 모습을 보인다. 또한 생성된 문장의 전체적인 문맥이 부자연스러우며 통사적으로 부적절한 모습도 보인다. 이는 코퍼스 내의 정보만으로 제한된 단어 조합만을 고려하는 N-gram 언어 모델의 한계로 보인다. 위 예제는 단순화를 위해 전처리와 규칙 처리를 최소화하였는데, 데이터셋을 늘리고 한국어 특징에 맞게 전처리를 진행한다면 보다 향상된 결과를 얻을 수 있을 것이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaSov8sY2w1s"
   },
   "source": [
    "<참고>\n",
    "\n",
    "> https://datascienceschool.net/view-notebook/a0c848e1e2d343d685e6077c35c4203b/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8lEfVvr2x7z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "실습 [9-1] N-gram 언어 모델로 문장 생성하기",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
